\documentclass[final,t]{beamer}

% poster template
\usepackage[orientation=portrait,size=a0,scale=1.4,debug]{beamerposter}
\usetheme{zurichposter}
\usepackage{graphicx}
\usepackage{varwidth}
% references
%\usepackage[bibstyle=authoryear, citestyle=authoryear-comp,%
%hyperref=auto]{biblatex}
%\bibliography{references}

%title

% document properties
\title{\LARGE HAShCache: Heterogeneity Aware Shared DRAMCache For Integrated Heterogenous Architectures}
\author{Adarsh Patil, R Govindarajan}
\institute{Department of CSA, Indian Institute of Science, Bangalore }


%------------------------------------------------------------------------------
\begin{document}

% my figures
\input{../figures}

\begin{frame}[t,fragile]{}
\begin{columns}[t]

%-----------------------------------------------------------------------------
%                                                                     COLUMN 1
% ----------------------------------------------------------------------------
\begin{column}{.47\linewidth}

	% intro HSA
    \begin{exampleblock}{Integrated Heterogenous Systems (IHS) Architecture}
    \begin{itemize}
    	\item \textit{Throughput-oriented} GPGPU SMs placed alongside \textit{Latency-oriented} CPU cores on-chip
   		\item Shared Physical and Virtual Address Space
		\item Unified Memory Hierarchy
		\item Cache Coherent Interconnect
    	\item Improved Programmability
    	\begin{enumerate}
	    	\item Avoids explicit management of data (memcpy, cudaalloc etc.)
	    	\item Allows pointer sharing
	    	\item Enables HLLs to exploit fine grained parallelism
    	\end{enumerate}
		\item AMD APUs, Intel Iris, NVIDIA Denver
    \end{itemize}
    \end{exampleblock}
% ----------------------------------------------------------------------------    
    % intro D$
    \begin{exampleblock}{Vertically Stacked DRAM}
    \begin{itemize}
        	\item Stacked using 2.5D interposer or 3D TSV
       		\item Large capacity \textasciitilde order of GBs
    		\item Very High Bandwidth \textasciitilde 500 GB/s (90GB/s DDR4)
    		\item 20 \% reduction in access latency
        	\item Samsung Wide IO, AMD/Hynix HBM, Intel/Micron HMC
        \end{itemize}
    \end{exampleblock}
% ----------------------------------------------------------------------------        
    % motivation
    \begin{exampleblock}{Motivation}
        \begin{itemize}
        	\item Contention for Cache Sets
       		\item Congestion in Memory controllers
       		\item CPU performance reduces due to co-running GPU
       		\item Adding a DRAM\$ naively does not provide sufficient improvements
       		\item GPU remains relatively unaffected by co-running
        \end{itemize}
        
    \end{exampleblock}
    
    
    \begin{figure}
       \includegraphics[scale=2.2]{../graphs/motivation-cpu}
       \includegraphics[scale=2.2]{../graphs/motivation-gpu}
       \caption{ANTT Improvement of CPU and GPU}
       \label{fig:motivation}
    \end{figure}
% ----------------------------------------------------------------------------    
    % bypass
    \begin{exampleblock}{Temporal Selective Bypass : \textit{ByE}}
    \begin{itemize}
	    \item Utilize the idle DRAM bandwidth
	    \item Bypass CPU requests to clean cache lines and cache misses
	    \item Achieved using a \textit{Bloom Filter} that tracks dirty lines in cache
	    \item Overhead: 256KB (4\% of cache capacity)
    \end{itemize}
    \end{exampleblock}

\end{column}


%-----------------------------------------------------------------------------
%                                                                     COLUMN 2
% ----------------------------------------------------------------------------
\begin{column}{.47\linewidth}
    % hsa arch
    %\begin{exampleblock}
    \begin{figure}
        \centering
        \hsacpu
        \caption{Architecture of a Integrated Heterogeneous System with DRAM Stacking}
        \label{fig:hsa-arch}
    \end{figure}
    %\end{exampleblock}
% ----------------------------------------------------------------------------
    % Design
    \begin{exampleblock}{HAShCache Design for IHS Processors}
        \large Large Metadata overhead \\
        \normalsize \qquad- Tags-in-DRAM, 128 Byte TAD Units \\
        \large Set Associativity \\
        \normalsize \qquad- Direct Mapped to avoid multiple tag lookups \\
        \large Miss Penalty \\
        \normalsize \qquad- Initiate early access to memory for CPU using a miss predictor \\
        \large RBH vs BLP addressing scheme \\
        \normalsize \qquad- Despite higher BLP, DRAM\$ performs better using RBH addressing\\
        \large Effect of Interference \\
        \normalsize \qquad- DRAM\$ must try to regain CPU performance lost due to interference\\
    \end{exampleblock}
    
% ----------------------------------------------------------------------------    
    % chaining
    \begin{exampleblock}{Spatial Occupany Control : \textit{Chaining}}
    \begin{itemize}
	    \item Improve GPU hit rates in cache by providing pseudo-associativity
	    \item Provides guaranteed occupancy for CPU lines in the cache
	    \item GPU requests placed in an adjoining "\textit{chained}" set in the same row on a set conflict with another GPU line
    \end{itemize}
    \end{exampleblock}
    
    \begin{figure}
        \centering
        %\chainaccess
        \caption{2KB DRAM\$ Row buffer and the access path for chaining}
        \label{fig:hsa-arch}
    \end{figure}
    
\end{column}

\end{columns}

\end{frame}

\end{document}
