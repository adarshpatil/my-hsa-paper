\section{Chaining Mechanism} \label{mechanism}
\subsection{Stacked DRAM Organization} \label{rbhvblp}
As discussed in Section \ref{motivation} we propose to use the stacked DRAM capacity as a large last level cache. PISONCache uses a direct mapped cache as proposed in \cite{alloy} and commercially adopted in the stacked MCDRAM on the Knights Landing generation of the Intel XeonPhi processor \cite{xeonphi}. In this organization the metadata is stored as a TAD (Tag-and-Data) unit alongside the data and is retrieved from the DRAM in multiple bursts. These stacked DRAM provide large amount of bandwidth using a large number of smaller capacity banks and TSV to transfer data. This exploit this abundant Bank Level Parallelism PISTONCache to modifies the address mapping scheme to map a single cache line across different banks within the same channel (vault). Contrary to popular belief this organization exploits the higher BLP as opposed to RBH. Since the data in the cache correspond to cache lines and even consecutive addresses are mapped to different cache sets stored in different rows, the DRAMCache inherently does not see high row buffer hit rates.