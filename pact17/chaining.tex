\section{PISTONCache Organization} \label{mechanism}
\subsection{Stacked DRAM Organization} \label{rbhvblp}
PISONCache builds on a direct mapped cache as proposed in \cite{alloy} and as commercially adopted in the stacked MCDRAM on the Knights Landing generation of the Intel XeonPhi processor \cite{xeonphi}. In this organization the metadata is stored as a TAD (Tag-and-Data) unit alongside the data and is retrieved from the DRAM in multiple bursts. To improve the hit latency the Alloy Cache Design uses a MAP-I prediction structure which starts early access to memory if the request is predicted to be a miss in the DRAMCache. Intuitively, as cpu requests are latency sensitive we adopt the MAP-I predictor for cpu requests and the gpu requests are served serially i.e. verify for tag match in the corresponding set, proceed to memory on a miss.
\subsection{Chaining Requests}
As observed in section \ref{motivation} there are contrasting design goals from the cache for the two heterogeneous processing elements. An important observation we make here is that the working sets of CPU applications tend to be limited to few tens of MBs due to the limited amount of MLP that can be exploited by the CPUs. Hence providing larger than certain partitions of cache leads to no improvement in hit rates and IPC. To accommodate these goals we use a technique inspired by the collision resolution mechanism of a hash map - namely open addressing. However, 