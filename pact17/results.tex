\section{Results} \label{results}
In this section, we evaluate the results of the discussed mechanisms for the DRAMCache. Figure \ref{results-antt-graph} (a) and (b) shows the ANTT improvement for CPU and GPU respectively for each schemes proposed over our a naive DRAMCache as discussed in \ref{design}. These results show the performance improvement obtained by our \cachename that is cognizant of the inherent heterogeneity of the requests.
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=1]{graphs/results-cpu-antt}
    \includegraphics[scale=1]{graphs/results-gpu-antt}
    \caption{ANTT Improvement of \cachename over naive DRAMCache for (a) CPU (b) GPU}
    \label{results-antt-graph}
\end{figure}

\subsection{PrIS DRAMCache scheduling}
Prioritizing CPU requests with our \prioname scheduler at the DRAMCache controller leads to considerable performance benefits for the CPU. The reduction in waiting and queuing time at the DRAMCache allow CPU requests to retrieve data from DRAMCache much more rapidly. As expected the performance of the CPU improves by a 35\% over a naive DRAMCache. However, on the flip side giving aggressive priority to all CPU requests reduces the performance of GPU by 10\% despite the GPU being able to tolerate larger memory access latencies. Our mechanisms further aim to reduce this performance drop for the GPU by ensuring (a) there are fewer CPU requests in the DRAMCache queues (b) GPU requests despite having higher latency at DRAMCache do not encounter double queueing latency due to many GPU misses going to the DRAM.
\subsection{ByE for Temporal bypass}
\par \bypassname attempts to achieves improved performance by directing some request to be served from the off-chip DRAM, thus achieving improved resource utilization and bandwidth balance in the process. \bypassname alone achieves 12\% improvement in CPU performance and a 3\% improvement in GPU performance. The CPU performance improvements are primarily due to bypassed requests facing reduced queuing delays at DRAM. The high hit rates for GPUs at the DRAMCache ensure fewer GPU requests at the off-chip DRAM which leads to lesser congestion. The bypassed CPU requests reduce some amount of queuing latencies for GPU which in-term leads to small performance benefits for the GPU as well.
\par Combining \bypassname with \prioname allows for the non-bypassed CPU requests at the DRAMCache to be served without further queuing delays. \bypassname + \prioname performs better than \prioname by 10\% for CPU and 7\% for GPU. Overall \bypassname + \prioname achieves 48.5\% improvement in CPU performance while degrading just 3\% GPU performance over a naive DRAMCache. Thus improving the overall system throughput by as much as 45.5\% over a un-optimized DRAMCache.

\subsection{Chaining for Spatial Occupancy Control}
Occupancy control is achieved by set chaining which improves hit rates for GPU in the DRAMCache while guaranteeing some occupancy for the CPU in the DRAMCache. We empirically determine the low occupancy threshold of the CPU (\textit{$l_{cpu}$}) in the cache to be 25\% for all our workloads. Occupancy control merely confines the cache sharing limits for each processor. Set chaining alone performs no better than a naive cache as the queuing latencies overwhelm any improvements in hit rates. However, when this mechanism is coupled with \prioname the increased hit rates improve the performance of the GPU by 3\%. For the CPU guaranteed occupancy in the DRAMCache and the secondary effect of lower congestion at DRAM allows CPU requests to be serviced with lower delays. This improves performance of CPU by 7\%, over only \prioname.
\par Overall set chaining + \prioname improves CPU performance by 44.7\% while degrading GPU performance by merely 7\% over a naive DRAMCache. This improves overall system throughput by a significant 37.7\% over a un-optimized DRAMCache.

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=1]{graphs/results-cpu-speedup}
    \includegraphics[scale=1]{graphs/results-gpu-speedup}
    \caption{Speedups obtained by adding a stacked DRAMCache for (a) CPU (b) GPU}
    \label{results-antt-speedup}
\end{figure}

\subsection{System Performance with Stacked DRAMCache}
We now holistically examine the benefits obtained by adding a stacked DRAM over a IHS processor and using this as a hardware managed cache. Figure \ref{results-antt-speedup} plots the speedups over Harmonic mean of IPCs obtained for each processor by using a stacked DRAMCache in various configurations. The figure also shows the performance of each processor running alone with a stacked DRAMCache that represents the ideal upper limit with no interference. 
We observe that, where adding a naive DRAMCache can achieve only an average of (42\%,24\%) improvement in (CPU,GPU) performance, our \cachename achieves significant speedups of (205\%,17.5\%) and (211\%,20.4\%) for (CPU,GPU) using Heterogeneity aware temporal bypass and spatial occupancy control schemes. This comes within 16\% and 13\% of the ideal no interference performance for the GPU and within 81\% and 76\% of the ideal no interference performance for the CPU for each of the schemes. Further, for memory intensive combination of CPU and GPU workloads like Qg7 and Qg8 which see significant degradation in performance of both processors due to interference, adding a DRAMCache can improve performance upto 430\% for CPU and 47\% for GPU over a baseline system with no stacked DRAMCache.