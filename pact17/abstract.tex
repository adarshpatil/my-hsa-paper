\begin{abstract}

Modern Integrated Heterogeneous processors chips pack throughput oriented GPGPU cores alongside latency oriented CPUs on the same die. These GPUs share virtual and physical address spaces and unify the memory hierarchy. These Integrated Heterogeneous Systems (IHS) allow for easier programmibility, data management and efficiency and are being increasingly adopted in HPC systems. Improving the performance of these systems  using precious on-chip resources does not scale due to larger working sets of the workloads. Our proposal adds a large capacity stacked DRAM whose high bandwidth can benefit the GPU cores and lower access latencies can improve CPU performance. We use this capacity as a hardware managed cache to improve the overall system performance of IHS processors. However, adding the DRAMCache naively, leaves significant room for performance improvement due to interference between the processors.
\par On the one hand latency sensitive CPU requires improved hit times and lower miss penalty while GPU can tolerate longer latencies for improved hit rates. Hard partition of cache resources or organizing the cache for one type of processor leads to idling and sub-optimality. \cachename achieves these goals to each processor using lightweight and dynamic techniques while not compromising on the design goals. The cache remains a latency optimized direct mapped Alloy cache when only CPU is running. In the case when GPU is running, the latency sensitive CPU requests temporally bypass to avoid being congested at the DRAMCache and utilizing the off-chip DRAM memory. For CPU requests that are queued at the DRAMCache we apply staged FR-FCFS prioritization to improve access latency. \cachename further applies occupancy control by providing psuedo associativity for GPU to improve hit rates. Overall our mechanism achieves X\% improvement over a naive DRAMCache and y\% over a baseline system with no stacked DRAMCache.

\end{abstract}