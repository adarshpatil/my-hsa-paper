\begin{abstract}

Integrated Heterogeneous Systems(IHS) processors pack throughput oriented GPGPUs alongside latency oriented CPUs on the same die. 
These CPU and GPU cores share certain resources, e.g., shared last level cache, network-on-chip(NoC), and the main memory. They also share virtual and physical address spaces and unify the memory hierarchy. The IHS architecture allows for easier programmibility, data management and efficiency. However, the increased demand for cache, memory bandwidth and shared resources coupled with the heterogeneous/disparate nature of the requests poses significant problems in exploiting the full potential of these architectures.
\par In this paper, we propose adding a large capacity stacked DRAM, used as a shared last level cache, for the IHS processors. The expectation is that the high bandwidth offered by the stacked DRAM cache would benefit the bandwidth-hungry GPU cores, while the lower access latencies of the stacked DRAMCache would improve the performance of latency-sensitive CPU cores. However, adding the DRAMCache naively, leaves significant room for performance due to the disparate demands from  CPU and GPU cores for DRAMCache and memory accesses. Further, we demonstrate that a naive implementation of DRAMCache results in significant queuing delays and hence a considerable increase in access latencies of the DRAMCache, necessitating a heterogeneity aware management of this shared resource for improved performance.
\par In this paper we propose three simple techniques to enhance the performance of CPU application while ensuring little to no performance impact to the GPU. More specifically, we propose prioritization of CPU requests at the DRAMCache controller, selective and temporal bypassing of CPU request at the DRAMCache and controlling the occupancy of GPU lines in the DRAMCache through pseudo-associativity. The resulting cache, \cachename, is aware of the inherent disparity of demands in an IHS architecture and can adapt dynamically to the requirements, when the GPU is active with a light weight scheme.
Experimental evaluation of the proposed \cachename results in a 45\% improvement in overall system throughput over a naive DRAMCache and over 200\% improvement over a baseline system with no stacked DRAMCache.

\end{abstract}
