\section{Related Work} \label{related-work}
State-of-art stacked DRAM device designs have primarily focused on improving the performance of multi-core architectures. Our work shows that there exists a large potential for performance improvements by using stacked DRAM in a IHS architecture. Principally there have been 2 schools of thought for using the stacked DRAM devices. In \cite{pom,cameo} the stacked DRAMs are organized as part of memory in lieu of the large capacities provided by these devices. The designs propose hardware management schemes for swapping hot pages into and out of the stacked DRAM devices. These designs can potentially suffer from large swapping overheads due to the large and disparate working sets of IHS workloads, thus increasing the number of hot pages in the system.
\par On the other hand, several designs propose to use the stacked DRAM as transparent hardware managed cache. In section \ref{design} we have broadly alluded to some of the works of DRAMCache designs and organizations \cite{alloy,atcache,bimodal,loh-hill}. Sectored caches such as \cite{footprint,unison-cache} allocate large blocks and avoid wastage of bandwidth by intelligently fetching useful blocks only. There are a number of designs around organizing DRAMCache at smaller system-sized blocks or an intermediate block size. These designs therefore have to intelligently manage metadata and tag lookup serialization by using approximate hardware structures. \cachename extends and adapts the simplicity and effectiveness of the Alloy Cache for IHS architecture after carefully considering the implications of each design on performance.
\par Orthogonal to these efforts, there have also been proposals such as \cite{software-dram} to expose the stacked DRAM to the applications and/or system software by providing special allocation calls to applications or using intelligent page management algorithms in system software to place hot data in the high bandwidth memory. Besides these designs suffering from the obvious overheads of software modification to improve performance, they also require a good understanding of program behavior and IHS architecture knowledge.
\par More notably, researchers have pointed out the need to utilize all the available bandwidth from both on-chip and off-chip DRAM devices due to comparable access latencies \cite{mostly-clean,mainak-hpca,bear} to extract best performance and improve resource utilization. However, \cachename uses the ingrained disparity in the requests rates and their implication on performance of each core to optimize bandwidth balance used in a heterogeneity aware manner. 
\par Complementary to our own, there have been efforts to improve performance of IHS systems in \cite{gpu-concurrency} by throttling the GPU cores using intelligent warp scheduling and avoiding congestion in the network-on-chip (NoC) \cite{interconnect}. To manage shared on-chip SRAM caches, Lee et al. \cite{tap} propose heterogeneity aware schemes that are built on top of UCP and RRIP schemes. Mekkat et al. \cite{helm} further propose shared SRAM cache management for IHS workloads that uses runtime metrics, like cache sensitivity of each workload, to allocate cache capacities. Despite larger capacities, DRAMCaches have higher latencies and hence will not be able to adapt quickly enough to SRAM occupancy management schemes proposed earlier.
\par Zhan et al. \cite{oscar} proposes improving performance of IHS architectures by replacing on-chip SRAM caches with slightly larger STT-SRAM caches that are non-volatile but have asymmetric read/write energy and latencies. The propose NoC reordering/batching schemes and differential CPU/GPU, read/write prioritization. Stacked DRAM are memory side caches and are not affected by NoC policies. 
\par Lastly, \cite{sms} propose staged memory scheduling for IHS processors and such heterogeneity aware schedulers can be leveraged in \cachename design to further improve performance.
% should we mention HSC coherence paper or sNeha agarwal papers?